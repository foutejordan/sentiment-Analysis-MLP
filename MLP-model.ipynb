{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f98753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78e688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>103158179306807296</td>\n",
       "      <td>positive</td>\n",
       "      <td>RT @MNFootNg It's monday and Monday Night Foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>103157324096618497</td>\n",
       "      <td>positive</td>\n",
       "      <td>All I know is the road for that Lomardi start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>100259220338905089</td>\n",
       "      <td>neutral</td>\n",
       "      <td>All Blue and White fam, we r meeting at Golden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9682</th>\n",
       "      <td>104230318525001729</td>\n",
       "      <td>positive</td>\n",
       "      <td>@DariusButler28   Have a great game agaist Tam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>100461938533863424</td>\n",
       "      <td>negative</td>\n",
       "      <td>I'm pisseeedddd that I missed Kid Cudi's show ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9684 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     label  \\\n",
       "0     264183816548130816  positive   \n",
       "1     263405084770172928  negative   \n",
       "2     262163168678248449  negative   \n",
       "3     264249301910310912  negative   \n",
       "4     262682041215234048   neutral   \n",
       "...                  ...       ...   \n",
       "9679  103158179306807296  positive   \n",
       "9680  103157324096618497  positive   \n",
       "9681  100259220338905089   neutral   \n",
       "9682  104230318525001729  positive   \n",
       "9683  100461938533863424  negative   \n",
       "\n",
       "                                                   text  \n",
       "0     Gas by my house hit $3.39!!!! I\\u2019m going t...  \n",
       "1     Theo Walcott is still shit\\u002c watch Rafa an...  \n",
       "2     its not that I\\u2019m a GSP fan\\u002c i just h...  \n",
       "3     Iranian general says Israel\\u2019s Iron Dome c...  \n",
       "4     Tehran\\u002c Mon Amour: Obama Tried to Establi...  \n",
       "...                                                 ...  \n",
       "9679  RT @MNFootNg It's monday and Monday Night Foot...  \n",
       "9680  All I know is the road for that Lomardi start ...  \n",
       "9681  All Blue and White fam, we r meeting at Golden...  \n",
       "9682  @DariusButler28   Have a great game agaist Tam...  \n",
       "9683  I'm pisseeedddd that I missed Kid Cudi's show ...  \n",
       "\n",
       "[9684 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extraction des data\n",
    "def get_data (url):\n",
    "    data = pd.read_csv(url,sep=\"\\t\", header=None)\n",
    "    data.columns = [\"id\", \"label\", \"text\"]\n",
    "    return data\n",
    "\n",
    "train_data = get_data('twitter-2013train-A.txt')\n",
    "dev_data = get_data('twitter-2013dev-A.txt')\n",
    "test_data = get_data('twitter-2013test-A.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ed9ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23849\n"
     ]
    }
   ],
   "source": [
    "#2) Mise en place du lexique du corpus\n",
    "#nous supprimons toutes les ponctuations\n",
    "# avec string.punctuation: !\"#$%&'()*+, -./:;?@[\\]^_`{|}~\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('','', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "#nous supprimons les espaces en trop dans un tweet\n",
    "def remove_whitespace(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "#tokenisation\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "#Amelioration\n",
    "#Supprimons la casse\n",
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "#Stemming: Ne garder que la racine des mots\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def stem_words(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = [stemmer.stem(word) for word in tokens]\n",
    "    return stems\n",
    "\n",
    "#Suppression des mots outils, des mots qui n'apporte pas d'information donc on peut les retirer sans affecter le sens de la phrase\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'));\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "#construction du lexique\n",
    "\n",
    "def create_lexique(data):\n",
    "    lexique = []\n",
    "    for tweet in data['text']:\n",
    "        lower_tweet = text_lowercase(tweet)\n",
    "        tweet_without_punctuation = remove_punctuation(lower_tweet)\n",
    "        new_tweet = remove_whitespace(tweet_without_punctuation)\n",
    "        tokens = tokenization(new_tweet)\n",
    "        tokens_with_stemming = stem_words(tokens)\n",
    "        tokens_wthout_stpWords = remove_stopwords(tokens_with_stemming)\n",
    "        for word in tokens_wthout_stpWords:\n",
    "            if word not in lexique:\n",
    "                lexique.append(word)\n",
    "    return lexique\n",
    "    \n",
    "train_data_lexique = create_lexique(train_data)\n",
    "\n",
    "#train_data_lexique\n",
    "len(train_data_lexique)\n",
    "print(len(train_data_lexique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eed699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23849"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assignation d'un numero unique a chaque lexique\n",
    "\n",
    "def assign_id_to_lexique(lexique):\n",
    "    new_lexique = {}\n",
    "    for i in range(1,len(lexique)+1):\n",
    "        new_lexique[lexique[i-1]] = i\n",
    "    return new_lexique\n",
    "\n",
    "train_lexique_with_id = assign_id_to_lexique(train_data_lexique)\n",
    "len(train_lexique_with_id)\n",
    "\n",
    "#test_lexique_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65caaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 1]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#4) Decomptage pour chaque message, le nombre d'occurence des mots\n",
    "# [0 for i in range(len(train_data['text'])]\n",
    "\n",
    "\n",
    "def words_occurence(data, data_lexique_with_id):\n",
    "    tab = []\n",
    "    for tweet in data['text']:\n",
    "        vector = [0 for i in range(len(data_lexique_with_id)+1)]\n",
    "        for word in tokenization(tweet):\n",
    "            if word in data_lexique_with_id.keys():\n",
    "                vector[data_lexique_with_id[word]] +=1\n",
    "               \n",
    "        tab.append(vector)\n",
    "    return np.array(tab)\n",
    "\n",
    "train_tab = words_occurence(train_data, train_lexique_with_id)\n",
    "dev_tab = words_occurence(dev_data, train_lexique_with_id)\n",
    "test_tab = words_occurence(test_data, train_lexique_with_id)\n",
    "\n",
    "print(train_tab)\n",
    "print(dev_tab)\n",
    "print(test_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b5384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9684, 23850)\n",
      "(3547, 23850)\n",
      "(1654, 23850)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def returnlabelVector(data):\n",
    "    label_vector = []\n",
    "    for label in data['label']:\n",
    "        if label == 'positive':\n",
    "            label = 0\n",
    "        elif label == 'negative':\n",
    "            label = 1\n",
    "        elif label == 'neutral':\n",
    "            label = 2\n",
    "        label_vector.append(label)\n",
    "    return np.array(label_vector)\n",
    "\n",
    "train_label_vector = returnlabelVector(train_data)\n",
    "test_label_vector = returnlabelVector(test_data)\n",
    "dev_label_vector = returnlabelVector(dev_data)\n",
    "print(train_tab.shape)\n",
    "print(test_tab.shape)\n",
    "print(dev_tab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f6ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e03f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "        \n",
    "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1cbb8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0, 2, 1, 0, 2, 2, 2, 0, 2, 1, 0, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0,\n",
      "        0, 0, 2, 1, 2, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 1, 2, 2,\n",
      "        2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 0, 0, 2, 2, 2, 0, 1,\n",
      "        2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 2, 0, 2,\n",
      "        2, 1, 0, 2]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0, 0, 2, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 0,\n",
      "        0, 1, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 0, 2,\n",
      "        2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0,\n",
      "        2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0,\n",
      "        0, 2, 2, 2]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0, 0, 2, 0, 1, 0, 0, 0, 1, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 2, 1, 2, 2, 0,\n",
      "        0, 1, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 0, 0, 2,\n",
      "        2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0,\n",
      "        2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0,\n",
      "        0, 2, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "traindata = Data(train_tab, train_label_vector)\n",
    "testData = Data(test_tab, test_label_vector)\n",
    "devData = Data(dev_tab, test_label_vector)\n",
    "print(traindata[100:200])\n",
    "print(testData[100:200])\n",
    "print(devData[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1e0dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(traindata, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(testData, batch_size=64, shuffle=True)\n",
    "dev_dataloader = DataLoader(devData, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c3771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(23850, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(32, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e6418ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear1): Linear(in_features=23850, out_features=64, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (linear3): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5b47f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "    # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "         # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    true_positive, true_negative, false_positive, false_negative = 0, 0, 0, 0\n",
    "    CM=0\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            CM+=confusion_matrix(y, pred.argmax(1),labels=[0,1,2])\n",
    "            \n",
    "        tn=CM[0][0]\n",
    "        tp=CM[1][1]\n",
    "        fp=CM[0][1]\n",
    "        fn=CM[1][0]\n",
    "        recall=tp/(tp+fn)\n",
    "        precision=tp/(tp+fp) \n",
    "        f_score = (2 * recall * precision )/(recall + precision)\n",
    "        print('Confusion Matirx : ')\n",
    "        print(CM)\n",
    "        print('- recall : ',(tp/(tp+fn))*100)\n",
    "        print('- Precision: ',(tp/(tp+fp))*100) \n",
    "        print('f_score: ', f_score*100)\n",
    "            \n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "   \n",
    "    \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0cc5f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.833301 [    0/ 9684]\n",
      "loss: 0.734077 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 713  121  641]\n",
      " [ 166   69  324]\n",
      " [ 283  118 1112]]\n",
      "- recall :  29.361702127659573\n",
      "- Precision:  36.31578947368421\n",
      "f_score:  32.470588235294116\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.004964 \n",
      "\n",
      "loss: 0.634094 [    0/ 9684]\n",
      "loss: 0.751834 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 604  112  759]\n",
      " [ 124   58  377]\n",
      " [ 177  102 1234]]\n",
      "- recall :  31.868131868131865\n",
      "- Precision:  34.11764705882353\n",
      "f_score:  32.95454545454546\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 1.005954 \n",
      "\n",
      "loss: 0.840187 [    0/ 9684]\n",
      "loss: 0.725610 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 761  130  584]\n",
      " [ 183   68  308]\n",
      " [ 322  132 1059]]\n",
      "- recall :  27.091633466135455\n",
      "- Precision:  34.34343434343434\n",
      "f_score:  30.28953229398664\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 1.007666 \n",
      "\n",
      "loss: 0.731895 [    0/ 9684]\n",
      "loss: 0.752137 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[815 169 491]\n",
      " [200  92 267]\n",
      " [401 194 918]]\n",
      "- recall :  31.506849315068493\n",
      "- Precision:  35.24904214559387\n",
      "f_score:  33.27305605786618\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.017065 \n",
      "\n",
      "loss: 0.802745 [    0/ 9684]\n",
      "loss: 0.675633 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 661  113  701]\n",
      " [ 144   62  353]\n",
      " [ 236  105 1172]]\n",
      "- recall :  30.097087378640776\n",
      "- Precision:  35.42857142857142\n",
      "f_score:  32.54593175853018\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.005861 \n",
      "\n",
      "loss: 0.656920 [    0/ 9684]\n",
      "loss: 0.673378 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 716  150  609]\n",
      " [ 167   77  315]\n",
      " [ 303  130 1080]]\n",
      "- recall :  31.557377049180328\n",
      "- Precision:  33.92070484581498\n",
      "f_score:  32.6963906581741\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.010187 \n",
      "\n",
      "loss: 0.742891 [    0/ 9684]\n",
      "loss: 0.736063 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 505  106  864]\n",
      " [  89   51  419]\n",
      " [ 114   72 1327]]\n",
      "- recall :  36.42857142857142\n",
      "- Precision:  32.48407643312102\n",
      "f_score:  34.34343434343434\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.011462 \n",
      "\n",
      "loss: 0.816996 [    0/ 9684]\n",
      "loss: 0.733771 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 697  139  639]\n",
      " [ 163   68  328]\n",
      " [ 280  122 1111]]\n",
      "- recall :  29.43722943722944\n",
      "- Precision:  32.850241545893724\n",
      "f_score:  31.050228310502288\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.008820 \n",
      "\n",
      "loss: 0.672682 [    0/ 9684]\n",
      "loss: 0.752423 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 723  139  613]\n",
      " [ 172   72  315]\n",
      " [ 303  125 1085]]\n",
      "- recall :  29.508196721311474\n",
      "- Precision:  34.12322274881517\n",
      "f_score:  31.648351648351646\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.008106 \n",
      "\n",
      "loss: 0.807560 [    0/ 9684]\n",
      "loss: 0.641615 [ 6400/ 9684]\n",
      "Confusion Matirx : \n",
      "[[ 677  124  674]\n",
      " [ 152   64  343]\n",
      " [ 253  111 1149]]\n",
      "- recall :  29.629629629629626\n",
      "- Precision:  34.04255319148936\n",
      "f_score:  31.68316831683168\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.007094 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epochs in range(0, 10):\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader,model,loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b929b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "#Accuracy : 56.6%\n",
    "#recall : 36,2%\n",
    "#precision: 34,04%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
